# 브라우저의 동작 원리
    - 사용자가 참조하고자 하는 웹페이지를 서버에 요청하고 서버의 응답을 받아 브라우저에 표시하는 것
    - 서버로부터 HTML, CSS, JavaScript, image 파일 등을 응답받음
    - HTML, CSS 파일은 렌더링 엔진의 HTML 파서와 CSS 파서에 의해 파싱되어 DOM, CSSOM 트리로 변환되고 렌더링 트리로 결합
    - 자바스크립트는 렌더링 엔진이 아닌 자바스크립트 엔진이 처리!
        - HTML 파서는 script 태그를 만나면 자바스크립트 코드를 실행하기 위해 DOM 생성 프로세스를 중지하고 자바스크립트 엔진으로 제어 권한을 넘김
        - 자바스크립트 엔진은 script 태그 내의 자바스크립트 코드 또는 script 태그의 src 어트리뷰터에 정의된 자바스크립트 파일을 로드하고 파싱하여 실행
        - 자바스크립트의 실행이 완료도면 다시 HTML 파서로 제어 권한을 넘겨 DOM 생성 재개
    - 브라우저는 동기적으로 HTML, CSS, Javascript를 처리하기 때문에!!
        - script 태그의 위치에 따라 블로킹이 발생하여 DOM의 생성이 지연될 수 있음
        - 따라서 script 태그의 위치는 중요한 의미를 가짐
            - body 요소의 가장 아래에 자바스크립트를 위치시킴
                - HTML 요소들이 스크립트 로딩 지연으로 인해 렌더링에 지장 받는 일이 발생하지 않아 페이지 로딩 시간이 단축됨
                - DOM이 완성되지 않은 상태에서 자바스크립트가 DOM을 조작하면 에러발생할 수 있음
    - 브라우저의 기본적인 역할은 HTML, CSS 명세에 따라 HTML 파일을 해석하여 표시
    - 브라우저 구성 요소
        - 사용자 인터페이스 (UI)
        - 브라우저 엔진
            - Chrome - blink
            - Safari - webkit
            - firefox - Gecko
        - 렌더링 엔진
        - 통신
        - UI 백엔드
        - 자바스크립트 해석기
        - 자료 저장소
        - etc
    - 렌더링 엔진은 HTML 문서를 파싱해서 DOM 트리를 구축
    - CSS 마크업을 파싱해서 앞서 구축한 DOM 트리와 함께 렌더링 트리를 만듦
        - 렌더링 트리는 화면에 보여줄 것들만 가지고 있는 트리로 구축이 되면 순차적으로 화면에 배치
    - 부모에서 자식 순서로 배치가 진행되며, 완료되면 그리기를 시작한다.

# script 태그의 async와 defer 속성
    - 일반적으로 <script> 요소를 통해 HTML 파일에 자바스크립트 파일을 포함
    - <script> 요소를 이용해 inline으로 자바스크립트를 작성하거나 src 속성에 자바스크립트의 위치를 지정해서 외부 스크립트를 불러올 수 있음!
    - 일반적으로 <script>는 HTML의 <head> 요소 안에 작성
        - 이곳에 작성하면 css 등 외부로부터 불러오는 리소스 파일을 한군데에서 관리할 수 있는 장점이 있음
            - ex)
                <!doctype html>
                <html>
                    <title>TITLE</title>
                    <link href="stylesheet.css" rel='stylesheet" type="text/css">
                    <script src="script.js"></script>
                    <body>
                        ...
                    </body>
                </html>
            - 브라우저가 HTML 렌더링에 영향을 줌
            - HTML을 파싱하는 동안 브라우저는 <script>를 만날 때마다 파싱을 중지하고 스크립를 로드하고 실행하게 됨
            - 이 과정에서 외부 스크립트를 로드하는 네트워크 왕복 시간, 자바스크립트를 실행하는 시간만큼 렌더링이 지연됨
    - 그래서 최근 웹에서는 일반적으로 <script>를 <body>의 맨 아래에 삽입함
        - body의 내용이 렌더링 된 이후에 script를 만나 로드하고 실행하기 때문에 렌더링 타이밍이 빨라진다.
        - 또한 스크립트가 렌더링 된 DOM에 접근할 수 있는 장점이 있음
    - defer
        - <script>는 다운로드와 실행이 순차적으로 진행되는 것과 달리 defer 속성을 가진 스크립트는 <script defer>를 만났을 때 다운로드를 시작하지만, HTML 파싱을 막지 않고 </html>을 만났을 때 실행함
        - 주로 DOM을 조작하는 내용이 포함되는 것이 좋음
        - 하지만 일부 브라우저에서는 defer 속성을 지원하지 않음을 주의
    - async
        - <script>, <script defer>와 마찬가지로 브라우저가 해당 요소를 만났을 때 외부 스크립트 다운로드 시작
        - defer와 마찬가지로 다운로드 중에 HTML 파싱을 막지 않지만 다운로드가 완료되면 즉시 실행하고, 실행하는 동안 브라우저는 HTML 파싱을 멈춤
        - 주로 DOM을 조작하지 않으며, 앞뒤에 로드되고 실행될 스크립트와 의존성이 없는 코드만 포함하는 것이 좋음

# Web protocol
    - 웹에서 쓰이는 통신 규약
    - Http 통신
        - 웹 프로토콜 중 하나로 Http가 가장 많이 쓰이며 HyperText Transfer Protocol의 약자
        - 인터넷에서 데이터를 주고 받을 수 있는 통신 규약이며, 요청과 응답으로 구성됨
    - Http 1.1과 2.0의 차이
        - 속도 차이!
            - 2.0은 헤더를 압축해서 보내기도 하고, 한번의 연결로 동시에 여러 메시지를 주고 받을 수 있다.

# HTTP와 HTTPS 통신 방식 차이
    - 결정적 차이는 보안!
    - Http 방식 vs Https
        - Http 방식은 네트워크 상에서 정보를 누군가가 마음대로 열람, 수정 가능
        - Http 방식이 Https 방식보다 빠름
        - Http 방식은 민감한 정보를 다룰 때 항상 변조, 해킹 가능성을 염두해야한다.
        - 설치 및 인증서를 유지하는데 추가적인 비용이 발생

# 함수형 프로그래밍
    - 설명
        - 순수함수와 보조함수의 조합을 통해 로직 내에 존재하는 조건문과 반복문을 제거하여 복잡성을 해결하고, 변수의 사용을 억제하여 상태 변경을 피하려는 프로그래밍 패러다임
    - 순수함수란?
        - 같은 입력이 주어지면, 같은 출력을 반환하고 사이드 이펙트가 없는 함수
        - 결국, 함수형 프로그래밍은 순수함수를 통해 사이드이펙트를 최대한 억제하여 오류를 피하고 프로그램의 안정성을 높이려는 방법
    - OOP와 차이점
        - OOP는 객체 안에 상태를 저장하고, 이 상태를 이용하여 메소드를 추가하고, 상태 변화를 설정하고 조정하기 위해 다양한 기능을 사용하지만, 함수형 프로그래밍은 상태를 저장하지 않고 없애는데 주력한다.

# CORS
    - Cross Origin Resource Sharing
    - 다른 도메인에서 리소스 요청 시, cross-origin HTTP에 의해 요청을 하는데, 대부분의 브라우저는 보안 상의 이유로 이 요청을 제한함. (Same Origin Policy)
        - 요청을 보내기 위해서는 요청을 보내는 대상과 프로토콜과 포트가 같아야 한다.
        - 같은 Origin에서만 리소스를 공유할 수 있다!
        - 하지만, 웹이라는 오픈스페이스 환경에서 다른 출처에 있는 리소스를 가져와 사용하는 일은 굉장히 흔해 무작정 막을 수 없다!
        - 그래서 몇 가지 예외 조항을 두고, 이 조항에 해당하는 리소스 요청은 출처가 다르더라도 허용하기로함!
    - 사실 출처가 다른 두 개의 어플리케이션이 마음대로 소통할 수 있는 환경은 위험함
        - 웹에서 돌아가는 클라이언트 어플리케이션은 사용자의 공격에 매우 취약함
            - 브라우저 개발자 도구만 열어도 모두 확인이 가능
            - 자바스크립트 소스 코드 난독화? -> 말그대로 난독화일뿐
        - 이러한 상황에서 다른 출처의 어플리케이션이 서로 통신하는 것에 대해 제약이 없다면?
            - CSRF / XSS와 같은 방법으로 어플리케이션에서 실행된 것처럼 꾸며 사용자의 정보를 탈취할 수 있다.
    - 같은 출처와 다른 출처의 구분
        - 출처를 비교하는 로직은 서버 스펙이 아니라 브라우저 스펙!
            - CORS 정책을 위반하는 리소스 요청을 하더라도 해당 서버가 같은 출처에서 보낸 요청만 받겠다는 로직을 가지고 있지 않다면? 서버는 정상 응답을 함
            - 하지만 브라우저에서 이 응답을 분석해 버릴 수 있음
            - 브라우저를 통하지 않고 서버 간 통신을 할 때는 이 정책이 적용되지 않음 
    - 동작 방식
        - 기본적으로 웹 클라이언트 어플리케이션이 다른 출처의 리소스를 요청할 때는 HTTP 프로토콜을 사용하여 요청하며, 이 때 요청 헤더에 Origin이라는 필드에 요청을 보내는 출처를 담아 보낸다.
        - 이 후 서버가 이 요청에 대한 응답을 할 때, 응답 헤더의 Acess-Control-Allow-Origin 이라는 값에 “이 리소스를 접근하는 것이 허용된 출처”를 내려준다.
        - 이 후 응답을 받은 브라우저는 자신이 보냈던 요청의 Origin과 서버가 보내준 응답의 Acess-Control-Allow-Origin을 비교하여 이 응답이 유효한 응답인지 아닌지를 결정한다
    - 기본적인 흐름은 간단하지만 CORS가 동작하는 방식은 세 가지 시나리오에 따라 변경 가능
        - Preflight request
            - 일반적으로 웹 어플리케이션을 개발할 때 가장 많이 마주치는 시나리오
            - 이 경우, 브라우저는 요청을 한번에 보내지 않고, 예비 요청과 본 요청으로 나누어서 서버로 전송함
            - 예비 요청을 Preflight라고 부르며, HTTP 메소드 중 OPTIONS 메소드가 사용된다.
            - 예비 요청의 역할은 본 요청을 보내기 전에 브라우저 스스로 이 요청을 보내는 것이 안전한지 확인하는 것
        - Simple request
            - preflight request를 보내지 않고 바로 서버에게 본 요청부터 함
            - 서버가 이에 대한 응답 헤더에 Access-Control-Allow-Origin과 같은 값을 보내주면 브라우저가 그때 CORS 정책 위반 여부를 검사하는 방식
            - 하지만 이 요청 방식은 특정 조건을 만족하는 경우에만 예비 요청을 생략할 수 있음
                - 요청 메소드는 GET, HEAD, POST 중 하나여야만 한다
        - Credentialed request
    - CORS 정책 위반 해결 방법
        - Access-Control-Allow-Origin 값 설정하기
        - webpack-dev-server로 프록싱하기

# Cross-Browsing
    - W3C에서 채택된 웹 표준에 따라 서로 다른 OS 또는 플랫폼에 따라 달리 구현되는 기술을 비슷하게 만듦과 동시에 어느 한쪽에 최적화되어 치우치지 않도록 공통 요소를 사용하여 웹 페이지를 제작하는 기법
    - 지원할 수 없는 다른 웹 브라우저를 위한 장치를 구현하여 모든 웹 브라우저 사용자가 방문했을 때 정보로서의 소외감을 느끼지 않도록 하는 방법론적 가이드를 의미
    - 브라우저별 렌더링 엔진이 어떠한 상황 속에서도 문제없이 동등하게 동작하는 것을 목표로함
        - 크로스 브라우징은 동일성을 의미하지 않는다.
        - 동등한 수준의 정보, 기능에 접근이 목표
    - 프론트엔드 개발자가 세울 수 있는 여러가지 전략 중 Feature detection( 기능 탐지 )을 사용해서 해당 기능이 해당 브라우저에 있는지를 확인하는 방법을 사용할 수도 있다.
    - 크로스 브라우징 대응 방법
        - CanIUse에서 사용하려는 CSS 프로퍼티가 어느 브라우저의 어느 버전까지 지원되는지 궁금할 때 확인 가능 / JS도 물론 확인 가능
        - 라이브러리 사용하기
            - jQuery
                - 자바스크립트 이벤트에 대해 크로스 브라우징 기능을 제공함
            - polyfil
            - reset.css or normalize.css 사용
            - prefix 사용
            - hack
            - IE 용 주석을 이용한 방법 등등

# polyfil

# SSR vs CSR
    - SSR
        - 전통적인 웹 방식을 의미하며 페이지가 새로고침 될 때마다 서버로부터 리소스를 전달받아 화면에 렌더링하는 방식
        - 하지만 React, Vue 등의 라이브러리가 등장하면서 훨씬 더 좋은 성능의 SPA 방식의 개발환경을 선호하기 시작!
        - TTV 이후, js 로직을 서버에서 받아온 뒤부터 TTI가 가능
    - CSR
        - 서버는 단지 JSON 파일을 보내주는 역할만 할 뿐이며, HTML을 그리는 역할을 클라이언트에서 수행
        - 자바스크립트가 모든 동작을 수행한 후 화면에 내용이 나타나므로 초기 구동속도는 SSR에 비해 느리다.
        - 또한 SEO를 할 수 없고 보안적으로 취약함
        - TTV와 TTI가 같은 시점에 이루어짐
    - SSG ( Static Site Generation )
        - React + Gatsby
            - 미리 정적인 HTML파일들을 만들어 놓을 수 있음
    - SSR과 CSR을 적절하게 섞어 사용하자
        - 첫번째 페이지 로딩에서는 SSR 사용하고 그 후에 모든 페이지 로드에는 CSR을 사용하는 방법을 많이 사용함
        - React에서는 Next.js, GatsbyJS / Vue에서는 Nuxt.js 등의 라이브러리가 SPA에서 SEO를 할 수 있도록 도와줌
            - Next.js의 경우, 전통적인 SSR이 아닌 SPA에서 SEO에 유리하기 위한 SSR을 도입하고, 그 이외에도 개발자들이 직접 Node에서 환경설정을 하지 않고도, 익숙한 툴을 가지고 설정을 할 수 있게 지원해준다.
            - 또는 CSR에서 메타 태그를 정의해주는 라이브러리를 사용하는 것도 방법!
                - react-helmet
                    - 동적으로 SEO에 필요한 메타태그들을 쉽게 변경할 수 있도록 도와주며, JSX 또는 TSX 내부에서 메타태그를 관리할 수 있다.

# MPA vs SPA
    - MPA (Multiple Page Application)
        - 사용자가 페이지를 요청할 때마다, 웹 서버가 요청한 UI와 필요한 데이터를 HTML로 파싱해서 보여주는 방식의 웹 어플리케이션
        - 사용자가 아주 사소한 요청을 해주어도 매번 전체 페이지를 렌더링해주어야 한다.
        - 장점
            - SEO 관점에서 유리함
            - MPA는 완성된 형태의 HTML 파일을 서버에서 전달받기에 검색엔진이 페이지를 크롤링하기에 적합
        - 단점
            - 매번 페이지 전체를 새로 불러와서 렌더링 해야하기 때문에 화면이 깜빡이는 등 성능상의 이슈
    - SPA (Single Page Application)
        - 하나의 HTML 파일을 기반으로 자바스크립트를 이용해 동적으로 화면의 컨텐츠를 바꾸는 방식의 웹 어플리케이션
        - 처음 한번만 정적 리소스를 다운받고, 그 이후에는 새로운 요청이 들어왔을 때 필요한 데이터만 부분적으로 바꾸어줌
        - 장점
            - 사용자 경험 측면에서 좋으며, 성능이 좋다.
            - 서버 없이도 개발 가능하며 디버깅이 상대적으로 쉽다
        - 단점
            - 초기에 웹 어플리케이션에 필요한 모든 정적 리소스를 다 받아야하기 때문에 초기 구동속도가 느리다.
            - SEO 관점에서 불리함

# Cookie / Session Storage / Local Storage
    - 모두 브라우저에서 데이터 저장소의 역할을 담당
    - Cookie
        - 클라이언트 로컬에 저장되는 키와 값이 들어있는 작은 데이터 파일
        - document.cookie하면 현재 쿠키 정보가 나옴
        - 사용자 인증이 유효한 시간을 명시할 수 있으며, 유효 시간이 정해지면 브라우저가 종료되어도 인증이 유지됨
        - 쿠키는 클라이언트의 상태 정보를 저장했다가 참조함
        - 클라이언트에 300개까지 쿠키 저장 가능 / 하나의 도메인당 20개의 값만 가질 수 있음, 하나의 쿠키값은 4kb까지 저장
        - Response header에 Set-Cookie 속성을 사용하면 클라이언트에 쿠키를 만들 수 있음
        - 쿠키는 사용자가 따로 요청하지 않아도 브라우저가 Request시 Request Header에 넣어서 자동으로 서버에 전송
       - 쿠키에 대한 정보가 계속적으로 서버 요청때 포함되므로 부담
    - Web storage
        - 웹 스토리지는 서버에 클라이언트 데이터를 저장하지 않음
            - 로컬 스토리지
                - 브라우저에 정보가 계속해서 남아있다.
            - 세션 스토리지
                - 해당 세션이 끝나고 나면, 즉 브라우저가 닫히면 데이터가 사라짐
        - 웹 스토리지는 데스크탑 기준 5~10MB의 저장 공간을 가지고 있어 쿠키에 비해 훨씬 저장공간이 큼 ( 모바일은 2.5MB )
            - 이것도 부족하다면 50MB를 기본적으로 저장할 수 있는 IndexedDB를 쓰자.

# Progressive Rendering
    - 서버에서 일부를 순차적으로 렌더링하면서 전체 페이지가 렌더링될 때까지 기다리지 않고 웹 페이지를 클라이언트에 스트리밍하는 기술
    - 인터넷 속도가 느리거나 불안정한 모바일 환경이 아직 남아있기 때문에 이럴 때 유용하게 사용함
    - 절차
        - 브라우저가 서버에 HTML을 요청!
        - 서버는 API 요청을 수행하고 서버에서 중요한 컨텐츠를 먼저 렌더링하여 브라우저로 스트리밍
        - 브라우저는 HTML 청크를 받아서 화면에 렌더링한다.
        - 서버는 중요 컨텐츠를 렌더링한 후 중요하지 않은 컨텐츠를 렌더링하고 이를 클라이언트로 스트리밍한다.
        - 브라우저는 나중에 중요하지 않은 컨텐츠를 받아서 렌더링
        - 전체 페이지가 로드되면 브라우저는 일반적으로 이벤트 핸들러 및 대화식 동작을 연결하는 DOM 요소에 대한 상호작용을 수화함
    - 관련 기술
        - 이미지 지연 로딩
            - 페이지의 이미지를 한꺼번에 로딩하지 않는다.
        - 보이는 컨텐츠의 우선순위 설정
            - 가능한 한 빨리 표시하기 위해 사용자 브라우저에서 렌더링될 페이지에 필요한 최소한의 CSS/Scripts/Contents만 포함하면 deferred 스크립트를 사용하거나 DOMContentLoaded / load 이벤트를 사용하여 다른 리소스와 내용을 로드할 수 있음

# Semantic Tag
    - 브라우저, 검색 엔진, 개발자 모두에게 컨텐츠의 의미를 명확하게 설명하는 역할을 함
    - Semantic Web
        - 웹에 존재하는 수많은 웹페이지들에 메타데이터를 부여하여, 기존의 잡다한 데이터 집합이었던 웹페이지를 '의미'와 '관련성'을 가지는 거대한 데이터베이스로 구축하고자 하는 발상

# <section>과 <article>의 차이
    - <section>
        - 보통 비슷한 특성의 컨텐츠를 담는 구역을 설정할 때 사용
    - <article>
        - 관련성이 없고 독립적인 내용들을 담을 때 사용
        - 예를 들어, <section> 안에서 서로 다른 기사들을 나열해야 할 때 사용함

# 여러 언어로 되어 있는 컨텐츠의 페이지를 어떻게 제공?
    - Http 요청을 서버에 보내면, 대게 요청하는 유저 에이전트가 Accept-Language 헤더와 같은 기본 언어 설정에 대한 정보를 보냄
    - 그 다음 서버는 이 정보를 사용하여 해당 언어가 제공 가능한 경우, 해당 언어 버전의 문서를 반환할 수 있다.
    - 반환된 HTML 문서는 <html lang="en">...</html>과 같이 <html> 태그에 lang 속성을 선언해야함

# img 태그에 srcset 속성을 사용하는 이유?
    - 기기의 디스플레이 너비에 따라 다른 이미지를 사용자에게 제공하고자 할 떄 사용함
    - ex> <img srcset="small.jpg 500w, medium.jpg 1000w, large.jpg 2000w" src="..." alt="..">
        - 첫번째 값은 이미지 이름 / 두번째 값은 픽셀 단위의 이미지 너비
        - 320px 너비의 경우,
            - 500 / 320 = 1.5625
            - 1000 / 320 = 3.125
            - 2000 / 320 = 6.25
        - 브라우저는 최소값에서 가장 위로 가까운 해상도를 사용
            - 해상도가 2x인 경우, 비율 값이 2에 가까운 1000w을 선택하게 됨
    
# 웹 페이지 최적화
    - 웹 브라우저가 하는 일 ( DOM, CSSOM을 만들고 렌더 트리로 결합하고 등등)을 구글에서는 Critical Rendering Path(CRP : 주요 렌더링 경로) 라고 부른다.
    - 사이트 최적화를 하는 방법 중 하나는 이 CRP를 간결하게 하는 것!
    - 방법
        - HTTP 요청 줄이기
        - CSS 스프라이트 사용하기
            - 여러 개의 이미지를 하나로 모아 이미지 파일의 갯수를 줄이는 방법
        - CDN (Content Delivery Network) 사용
            - 사용자 응답시간의 대부분이 구성 요소를 다운로드 받는데 사용된다.
            - CDN은 사용자에게 보다 효율적으로 컨텐츠를 제공하기 위해 여러 지역에 걸쳐 분산된 웹서버의 집합체로 사용자가 요청을 했을 때 고객의 네트워크에서 가장 가까운 서버를 축정하여 선택하기 때문에 가장 빠른 응답시간의 서버가 선택된다.
        - 캐시 만료일 설정
            - 설정하는 이유는 웹 페이지의 구성 요소인 HTML, CSS, JS, 이미지 등의 파일 등을 사용자 컴퓨터의 캐시에 저장해두고 재사용하기 위해서
            - 하지만 모든 구성 요소에 만료 날짜를 설정하는 것이 아니라 만료 날짜 동안 수정되지 않아도 문제가 되지 않을 요소들에게만 적용해야 한다.
        - Gzip
            - 압축을 통해서 파일 크기를 줄여 응답 시간을 줄일 수 있다.
            - 브라우저에서 사용되는 인코딩 종류는 Accept-Encoding이라는 Request Header의 attribute를 통해 서버쪽에 알려지며 서버쪽에서는 이 Accept-Encoding의 값을 보고 브라우저에서 decoding이 가능한 압축 파일을 보내게 된다.
            - Gzip은 파일의 압축에 사용되는 응용 소프트웨어이며 대부분의 브라우저에서 지원되기 떄문에 가장 대중적이며 효과적인 압축 방법
        - CSS는 최상단에!
            - CSSOM이 만들어지지 않으면 렌더링을 진행할 수 없다.
            - 따라서 브라우저가 빠르게 CSSOM을 빌드할 수 있도록, CSS는 <head> 바로 아래에 작성한다.
                <head>
                    <link href="style.css" rel="stylesheet">
                </head>
        - 자바스크립트 최적화
            - 자바스크립트는 DOM을 조작할 수 있기에 HTML 파싱을 막는다.
            - 즉, HTML을 읽다가 <script> 태그를 만나면 그 즉시 파싱은 중단되며, 이전까지 생성된 DOM만 다룰 수 있다.
            - 하지만 async나 defer 속성을 명시하면 파싱을 멈추지 않고 그대로 진행시킬 수 있다.
                - async
                    - HTML 파싱 중에 파일을 다운로드하고 다운로드가 완료되면 HTML 파서를 일시 중지하여 실행한다.
                    - 여러 외부 스크립트에 사용했을 때 순서를 보장하지않아 DOM 제어에 어려움이 있을 수 있으니 다른 스크립트에 의존하지 않는 경우 사용해라
                - defer
                    - defer는 HTML 파싱 중에 파일을 다운로드하고 파싱이 완료된 후, DOMContentLoaded 이벤트 이전에 실행됨
                    - DOM을 직접적으로 제어하는 코드가 있다면 defer로 실행
            - async나 defer는 브라우저별로 한계가 있음
        - 애니메이션 최적화
            - 가능한 자바스크립트보다 CSS로 처리하는 것이 좋다.
        - Javascript and CSS 파일을 외부로 분리하기
            - js와 css 파일을 문서 내에 배치하는 것보다 외부로 분리하여 link, script 태그로 불러오는 방식을 사용하는 방법으로 응답시간을 줄일 수 있다.
            - 브라우저에 의해 캐시에 저장된 js와 css 파일은 재사용되어 사용되기 때문이다!
        - Javascript and CSS 통합하기
            - 외부로 분리한 파일들을 최대한 통합하여 파일 갯수를 줄이는 것 또한 중요하다
            - 아무리 작은 파일이라도 사용자의 컴퓨터로 가져오기 위해서는 요청을 해야하고 요청이 많아지면 응답 시간 또한 늘어나기 때문에
        - DNS 서버 조회 줄이기
        - 중복 script 제거하기
        - 리다이렉트 피하기
            - 리다이렉트는 사용자를 한 URL에서 다른 URL로 다시 보내는 것을 말한다.
            - HTML 문서 모두 요청하기도 하며, 페이지 안에서 구성요소를 요청할 때도 사용된다.
        - 쿠키 사이즈 줄이기
        - iframe 갯수 줄이기
        - DOM 요소의 수를 줄이기 & DOM 접근을 최소화하기
        - Event Handler 잘 설정하기 ( 이벤트 위임을 통해 )

# CSRF or XSRF
    - Cross-Site Request Forgery
    - 공격자가 "사용자의 동의없이 / 사용자가 인지하지 못하는 상황에서" 브라우저로 하여금 서버에 어떤 요청을 보내도록한다.
    - XSS 공격으로 탈취한 정보를 이 때 사용할 수 있다.
    - 직접 사용자의 컴퓨터를 감염시키거나 서버를 공격해서 이뤄지는 공격이 아니라 특정 조건이 필요함
        - 위조 요청을 전송하는 서비스에 피해자가 로그인한 상태
        - 피해자가 공격자가 만든 피싱 사이트에 접속을 해야한다.
    - 방어 방법
        - Referrer 검증
            - HTTP Referer는 웹 브라우저를 사용할 때 하이퍼링크를 통해 사이트 방문시 남는 흔적으로, 어떤 사이트를 통해서 요청했는지 알 수 있다.
        - CSRF token 사용
            - 사용자의 세션에 임의의 난수 값을 저장하여 사용자의 요청마다 이 값을 포함시켜 전송한다.
            - 이후 백엔드 서버에서 요청을 받을 때마다 세션의 토큰 값과 요청 파라미터의 토큰 값이 일치하는지 검증

# XSS
    - Cross Site Scripting
    - 공격자가 클라이언트 코드에 악의적인 스크립트를 주입하는 공격
    - 방어
        - 위험할 수 있는 부분을 스크립트로 읽지 않고 문자로만 볼 수 있게 처리하는 것
            - 이 때 사용하는 것이 HTML entity인데, HTML의 문자들을 치환하여 보여주는 것

# Progressive enhancement ( 점진적 향상법 )
    - 오래된 기기 혹은 낮은 버전의 브라우저에 맞추고, 여러 테스트를 통해 기능을 점진적으로 향상시키는 것

# Graceful degradation ( 우아한 성능저하법 )
    - 최신 기술에 맞춘 후 오래된 기기 혹은 오래된 기술에서도 동작하도록 하기위해 최적화 시키는 것

# 구글 애널리틱스
    - 웹 사이트 방문자의 데이터를 수집해서 분석함으로써 온라인 비즈니스의 성과를 측정하고 개선하는데 사용하는 웹로그 분석 도구

# 표준모드와 쿼크모드
    - 두 가지 모두 브라우저가 가진 렌더링 모드
    - 브라우저는 DTD에 따라 렌더링할 모드를 선택하는데, 이를 Doctype sniffing 또는 Doctype switching이라고 한다.
    - 브라우저가 출력하고자 하는 문서가 최신이라면 W3C나 IETF의 표준을 엄격히 준수하는 표준모드로 렌더링한다.
    - 문서가 오래된 버전이라면 쿼크모드로 렌더링한다.
        - 이전 세대의 브라우저에 맞는 비표준 규칙을 문서에 적용해 오래된 웹페이지들이 최신 브라우저에서 깨져보이지 않게 한다.
    - 브라우저는 문서가 최신인지 아닌지를 DTD로 판한다.
        - 만약 DTD가 존재하지 않거나 일부가 누락된 경우 쿼크모드로 문서를 해석한다.

# data-* 속성
    - HTML5에서 새로 추가된 data-속성은 커스텀 데이터 속성으로 개발자가 임의로 이름을 붙일 수 있는 속성이다.
    - data- 속성은 <html> 태그 상에서 별다른 작용을 하지 않는다.
    - 자바스크립가 DOM의 데이터에 접근하거나 서버에서 받아온 데이터를 활용해야할 때 사용된다.
    - data-* 속성을 추가함으로써, 평범한 HTML 요소조차 복잡하고 강력한 프로그램 객체가 될 수 있다.

# 브라우저는 한 Domain에서 동시에 리소스를 몇 개 받을 수 있을까?
    - 브라우저마다 다르다.
    - 브라우저 벤더, 버전별로 상이하지만 메이저 브라우저들은 평균 6~8개의 리소스를 동시에 받을 수 있다.
    - 크로스 브라우징을 고려하면 평균적으로 6개라고 생각하면 된다.

# 웹 어플리케이션이나 사이트를 만들 때, 고려해야 할 UI, Security, Performance, SEO, Maintainability에 대해 설명하기
    - UI
        - PC용 웹 사이트와 모바일 사이트를 하나의 도메인에서 서비스하려면 반응형 디자인으로 페이지를 구현한다.
        - 또는 두 개의 도메인을 구분하려면 PC용, 모바일 용을 따로 디자인하여 퍼블리싱하면 된다.
    - Security
        - SPA 내에서 DOM에 직접적으로 접근하지 않고, FE 프레임워크 또는 라이브러리에서 권장하는 방식으로 접근하는 것
        - 입력 폼 양식에 대하여 유효성 체크를 FE, BE 둘 다 처리
            - 이렇게 했을 때 Invalid data나 잘못된 파일이 업로드 되었을 때의 피해를 최소화할 수 있다.
        - 페이지에 대한 router를 auth 처리하여 인증된 사용자만 접근할 수 있도록 구분한다.
        - LocalStorage 대신 SessionStorage를 사용하는 것도 좋은 방법
    - Performance
        - 기본적으로 style 태그는 head 내에 script태그는 최하단에 배치한다.
            - 브라우저에 의해 DOM이 생성되고 렌더링 되면서 우선적으로 style이 적용되어야 하고, script는 마지막에 불러와 로직이 적용되어야 하기 때문
        - Virtual DOM을 사용하는 것
        - 빌드할 때, Uglify, Minify, Gzip 프로세스를 추가하여 브라우저에서 JS나 CSS를 로드할 때의 시간을 최소화하면 성능 향상을 기대할 수 있다.
    - SEO
        - 검색 엔진 최적화를 위하여 <title>, <meta> 태그들에 대한 정보를 모두 입력한다.
        - Robot.txt를 사용한다.
    - Maintainability
        - 코드 컨벤션 정의
        - linter 사용

# DOCTYPE
    - 웹 표준을 지키는 문서 타입이 여러 종류가 존재
    - HTML, XHTML 등이 있고 각 문서들의 차이는 엄격하게 또는 느슨하게 보느냐

# XML과 XHTML
    - 웹 문서의 규격
    - XML
        - W3C에서 여러 특수 목적의 마크업 언어를 만드는 용도에서 권장되는 마크업 언어
        - XML은 문서 상의 데이터 이름과 값 등을 구분하기 위해 만들어짐
    - XHTML
        - XML 문법을 따르며, HTML 문법과 매우 유사하지만 더 엄격함
    - XHTML을 사용하면 할 수 있으나, HTML로는 불가능한 일이 있다.
    - HTML을 사용하면 할 수 있으나, XHTML로는 불가능한 일이 있다.
    - CSS를 이해하는 방식에 차이가 있다.
    - 클라이언트 쪽의 스크립트를 다루는 방식에 차이가 있다.
    - ex>
        tag 닫힘의 차이
        - HTML
            <img src="../img.png" alt="이미지는 스스로 닫는다">
            <p>HTML에서도 대부분의 태그는 닫혀야 제대로 동작</p>
            
            - img 태그는 br태그처럼 self closing tag로, 내부에 child를 가지지 않기 때문에 닫는 태그를 굳이 만들지 않아도 된다.
                - ex> <br>, <img>, <meta>, <link>, <input>, <hr>
        - XHTML
            - 모든 태그는 닫혀있어야 한다.
            <img src="../img.png" alt="닫혀있어야함" />

# meta 태그
    - HTML 문서가 어떤 내용을 담고 있고, 키워드는 무엇이며, 누가 만들었는지에 대한 정보, 즉 문서 자체의 특성
    - 대표적인 속성값으로는 subject, keywords, title, author 등이 있다.
    - 페이지에 대한 메타 정보로 검색 엔진에서 페이지에 대한 메타 정보를 데이터베이스화해서 검색 엔진에서 검색할 때 적잘한 페이지를 보여주도록 한다.
    - 또한 모바일에 대한 처리인 viewport를 지정할 수 있다.

# enctype 속성
    - <form> 태그의 속성인 method, action, enctype 등은 입력받은 데이터를 어떻게 처리할 것인지 세부적으로 설정하는데 사용
    - method -> 전송 방식
    - action -> 전송 목적지
    - enctype -> 전송되는 데이터 형식
        - application/www-form-urlencoded
            - default 값
            - enctype을 따로 설정하지 않으면 이 값이 설정됨
            - formData는 서버로 전송되기 전에 URL encode 됨
        - multipart/form-data
            - 파일이나 이미지를 전송할 경우 이 방식을 사용
            - 그렇게 하지 않으면 웹 서버로 데이터를 넘길 때 파일의 경로명만 전송되고 파일 내용이 전송되지 않음
            - 이때 HTTP 메소드는 post 값으로 지정해줘야함
        - text/plain
            - 이 형식은 인코딩을 하지 않은 문자 상태로 전송한다.

# Spring
    - Spring이란 Java 플랫폼을 위한 오픈소스 어플리케이션 프레임워크

# REST
    - Representational State Transfer의 약자
    - 자원을 이름으로 구분하여 해당 자원의 상태를 주고 받는 것을 의미
        - 자원의 표현에 의한 상태 전달
        - 데이터가 요청되어지는 시점에서 자원의 상태를 전달한다.
        - JSON 혹은 XML을 통해 데이터를 주고 받는 것이 일반적
    - HTTP URI를 통해 자원을 명시하고, HTTP Method를 통해 해당 자원에 대한 CRUD operation을 적용하는 것
    - 장점
        - HTTP 프로토콜의 인프라를 그대로 사용하므로 REST API 사용을 위한 별도의 인프라를 구축할 필요가 없다.
        - HTTP 표준 프로토콜에 따르는 모든 플랫폼에서 사용이 가능하다.
        - 서버와 클라이언트의 역할을 명확히 분리한다.
    - 단점
        - 사용할 수 있는 메서드가 4가지 밖에 없다.
    - REST 특징
        - 1. Server-Client 구조
        - 2. Stateless
            - HTTP 프로토콜은 Stateless Protocol이므로 REST 역시 무상태성을 갖는다.
            - Client의 context를 서버에 저장하지 않는다.
        - 3. Cacheable
            - 웹 표준 HTTP 프로토콜을 그대로 사용하므로 웹에서 사용하는 기존의 인프라를 그대로 활용할 수 있따.
                - 즉, HTTP가 가진 강력한 특징 하나인 캐싱 기능을 적용할 수 있다.
        - 4. Layered System 
            - 클라이언트는 REST API 서버만 호출한다.
            - REST 서버는 다중 계층으로 구성될 수 있따.
                - API 서버는 순수 비즈니스 로직을 수행하고 그 앞단에 보안, 로드밸런싱, 암호화, 사용자 인증 등을 추가하여 구조상의 유연성을 줄 수 있다.
                - Proxy, Gateway 같은 네트워크 기반의 중간 매체를 사용할 수 있다.
        - 5. Uniform Interface
            - URI로 지정한 리소스에 대한 조작은 통일되고 한정적인 인터페이스로 수행한다.
            - HTTP 표준 프로토콜에 따르는 모든 플랫폼에서 사용이 가능하다.
        - 6. Code-On-Demand (Optional)
            - 서버로부터 스크립트를 받아서 클라이언트에서 실행한다.
            - 반드시 충족할 필요없다.
    - RESTful이란?
        - 위의 REST 특징을 모두 만족하면 RESTful하다고 할 수 있다.

# OAuth
    - 인증을 위한 표준 프로토콜로 한 인터넷 서비스의 기능을 다른 서비스에서도 사용하도록 하는 것
    - ex
        - 어떤 쇼핑몰에서 상품을 하나 구매하는데 SNS에 홍보를 해주면 할인을 해준다고 합시다.
        - 사용자가 여기에 동의해서 SNS에 자동으로 홍보글을 작성했다.
        - 여기서 SNS에 자동으로 글을 작성한 것이 바로 OAuth를 활용한 것
    - OAuth와 OpenID
        - 둘 다 타 서비스에 접근해서 타 서비서의 인증과정을 경우해서 데이터를 이용한다는 점은 같지만 목적이 다르다.
        - OpenID
            - 단순히 사용자를 인증하고 로그인을 대리하는 것이 목적
        - Oauth
            - 로그인 후 타 서비스의 API를 활용해서 해당 이용자의 식별 정보 외에 다른 데이터들까지 활용하는 것이 목적
    - 인증 과정
        - 로그인을 하고 서비스를 사용하려는 사람을 사용자, 타사의 Oauth API를 이용하려는 서비스 제공자를 클라이언트, Oauth를 제공하는 곳을 서버라 칭하자.
        - 1. 사용자가 클라이언트 서비스에 접속
        - 2. 사용자가 로그인을 위해 서버의 Oauth 서비스를 선택한다.
        - 3. 사용자는 서버의 Oauth 패이지로 이동해 인증 과정을 거친다.
        - 4. 인증 과정이 끝나면 클라이언트가 지정한 URL로 서버에서 파라미터에 인증 코드를 붙여서 리다이렉트한다.
        - 5. 리다이렉트된 URL에 붙어온 파라미터를 읽고 클라이언트는 여기서 온 정보와 클라이언트 ID와 Secret을 붙여서 서버에 Access-Token을 요청한다.
        - 6. Access-Token을 제대로 받았다면 이 Access-Token으로 클라이언트는 사용자의 데이터를 서버에게 요청할 수 있다.
        - 7. Access-Token은 빠르게 만료되며 6 과정에서 받은 만료가 긴 Refesh-Toekn으로 재발급 받을 수 있다.
    - 인증 과정 ( 다르게 표현 )
        - 1. 등록
            - 서비스 제공자는 필요한 리소스를 얻기 위해 리소스 서버에 등록 요청을 한다.
            - 대부분의 경우 등록과 동시에 Client ID ( 우리의 서비스를 식별하는 값), Secret, Redirect URI을 제공 받는다.
            - 우리가 용하고자 하는 건 리소스 서버 측의 데이터 즉, 사용자 데이터이고 이를 이용할 수 있게 허락해주세요!라고 등록 요청을 한다.
            - 그에 대한 응답으로 너는 그런 요청을 보낸 몇번째 고객이며 너의 비밀번호는 이것이다.
            - 그리고 그러한 정보를 요청할 때는 지정된 URL을 명시에 가져가라 라고 등록하는 과정인 것
        - 2. Resource Owner의 승인
            - 예를 들어, 페이스북 로그인을 한다고 가정해보자.
            - 우리는 페이스북으로부터 클라이언트 ID와 secret, redirect 주소를 받았고 페이스북도 그 사실을 알고 있다.
            - 그 상태에서 유저가 우리의 사이트에 접근해 페이스북 로그인을 시도하는 경우 유저가 입력한 값은 페이스북 서버로 전송되며 페이스북은 그러한 클라이언트가 존재하는지 그리고 올바른 redirect uri인지 확인하고 Owner에게 동의를 받는 작업이 이루어 진다.
        - 3. Resource Server의 승인
            - 이 후, 리소스 서버의 승인 절차가 이루어 지는데 2단계에서 Owner의 승인이 끝나면 리소스 서버는 Authorization code값을 포함한 URL로 Owner를 강제로 리다이렉트 한다. 이 리다이렉트된 URL을 Client가 받아 URL에 있는 Authorization code 그리고 본인의 Client ID, secret을 리소스 서버에 다시 보내면 서버는 이 모든 정보를 확인한 후, 일치하는 경우 Access-Token을 발급힌다.
        - 4. Access-Token
            - 위의 절차를 통해 서버는 올바른 클라이언트인지 그리고 Owner의 승인을 확인 받은 후, 기존의 검증용 코드인 Authorization code를 삭제한다.
            - 그리고 이제서야 Access-Token을 Client에게 발급하는데 이 Access-Token이 포함하는 정보는 어떠한 유저가 어떠한 권한들을 클라이언트 서비스에 허용했으니 그러한 서비스를 클라이언트가 요청하면 허락한다. 라는 의미를 갖는다.
    - 리소스 서버는 Access-Token을 활용하여 API를 호출했을 때 확인하는 절차가 크게 2가지가 있다.
        - Access-Token을 URL에서 확인하는 방법
        - Oauth의 인증 방식인 Header에 Bearer 부분에 Access-Token을 작성하는 방법
    - 이 두 가지 방식을 통해 Access-Token에 대한 확인 일어나고 이를 통과한 경우 Json의 형태로 API 정보를 전달 받는다.
    - Refresh Token
        - 발급받은 Access-Token의 유효기간이 1시간에서 90까지로 다양하지만 일정한 시간 이후에는 토큰이 만료가 되며 만료된 토큰으로 API에 접근하는 것은 불가능하다.
        - 이 때마다 새로운 토큰을 발급받기 위해 위의 전체 과정을 다시해야하는가라는 고민에서는 그러기 싫고 이 관점에서 고안된 것이 Refresh Token이다.
        - 일반적으로 Access-Token을 발급받을 때 Refesh Token을 함께 발급 받는 경우가 많다.
        - 발급 받은 토큰으로 리소스 서버에서 데이터를 가져오다 토큰이 만료되면 우리는 인증 서버에 Refresh Token과 Client ID, Secret을 보내고 새롭게 Access-Token을 발급 받는다.
        - 이 때, 추가적으로 Refresh Token을 발급하는 경우도 있고, Refesh Token은 기존에 있는 것을 사용하고 Access-Token만 재발급하는 경우도 있다.

# 대칭키, 공개키
    - 대칭키
        - 암호를 만드는 행위인 암호화를 할 때 사용하는 일종의 비밀번호를 키라고 한다.
        - 이 키에 따라서 암호화된 결과가 달라지기 때문에 키를 모르면 암호를 푸는 행위인 복호화를 할 수 없다.
        - 대칭키는 동일한 키로 암호화와 복화를 같이 할 수 있는 방식의 암호화 기법을 의미한다.
        - 즉 암호화를 할 때 1234라는 값을 사용했다면 복호화를 할 때 1234라는 값을 입력해야 한다는 것이다.
        - 암호화를 시킨 파일은 암호화가 되어 전달되지만 파일을 해독하는 키는 암호화되지 않기 때문에 전달하는 과정에서 키가 노출될 수 있다.
    - 공개키
        - 대칭키 방식의 단점은 암호를 주고 받는 사람들 사이에 대칭키를 전달하는 것이 어렵다는 점
        - 대칭키가 유출되면 키를 획득한 공격자는 암호의 내용을 복호화할 수 있기 때문에 암호가 무용지물이 된다.
        - 개인은 공개키를 제공받고 제공받은 공개키를 통해 문서를 암호화한다.
        - 이를 다시 전송하면 공개키를 발행한 사람의 비공개키를 통해 복호화하고 관련작업을 수행
        - 공개키 방식은 두 개의 키를 갖게 되는데 A키로 암호화를 하면 B키로 복호화할 수 있고, B키로 암호화하면 A키로 복호화할 수 있는 방식
        - 이 방식에 착안해서 두 개의 키 중 하나를 비공개키, 나머지를 공개키로 지정
        - 비공개키는 자신만이 가지고 있고, 공개키를 타인에게 제공하며 공개키를 제공받은 타인은 공개키를 이용해서 정보를 암호화한다.
        - 암호화한 정보를 비공개키를 가지고 있는 사람에게 전송한다.
        - 비공개키의 소유자는 이 키를 이용해서 암호화된 정보를 복호화한다.
        - 이 과정에서 공개키가 유출된다해도 비공개키를 모르면 정보를 복호화할 수 없기 때문에 안전하다.

# JWT ( Json Web Tokens )

# WebRTC ( Web Real-Time Communication )
    - 웹 브라우저 간에 플러그인의 도움 없이 서로 통신할 수 있도록 설계된 API
        - 웹 브라우저 간에 Adobe flash나 ActiveX와 같은 별도의 플러그인 없이 서로 통신할 수 있도록 만든 기술
    - 음성 통화, 영상 통화, P2P 파일 공유등으로 활용될 수 있다.
    - 본래 첫 태생 자체는 P2P를 위한 통신 방식이었다.
    - webSocket을 이용하거나 하기 때문에 직접적으로 IP를 연결하는 방식을 차용한다. 그렇기 떄문에 방화벽이 존재하거나 허브 또는 라우터를 사용하는 NAT환경에서는 연결이 불가능하다.
        - 따라서 앞서 말한 시그널링을 위해서는 방화벽을 통과시켜주거나 private IP를 public IP로 바꿔주는 STUN, TURN 서버를 사용해야 함
        - 시그널링을 하고 연결을 하기 위해서 UDP Hole Punching 방식이라고 하는 방식을 사용하는데 중간에 무언가 중개해줘야할 누군가가 필요하다!
    - STUN 서버
        - Session Traversal Utilities for NAT
        - STUN은 클라이언트-서버 프로토콜이다.
        - STUN 클라이언트는 사설망에 위치하고, STUN 서버는 인터넷망에 위치한다.
        - STUN 클라이언트는 자신의 public IP 주소를 사전에 확인하기 위해 STUN 서버에게 요청하고, STUN 서버는 STUN 클라이언트가 사용하는 공인 IP 주소를 응답한다.
        - STUN 클라이언트는 자신이 사용할 공인 IP 주소를 알 수 없으므로 STUN 서버에게 자신의 공인 IP 주소를 요청한다.
        - STUN 메시지가 방화벽을 지날 때 네트워크 계층의 IP와 전송 계층의 포트 넘버가 바뀐다.
        - STUN 서버는 패킷의 IP헤더와 UDP헤더의 값과 STUN 메시지 안에 있는 STUN 클라이언트 IP 주소와 UDP 포트 넘버를 비교한다.
        - STUN 서버는 두 개의 서로 다른 주소에 대한 바인딩 테이블을 생성하고 요청에 대한 응답 메시지에 공인 IP 주소를 보낸다.
        - STUN 클라이언트의 주소는 호스트 주소 또는 단말 주소라고 하고, STUN 서버가 알려주는 주소는 Reflexive Transport Address 또는 Mapped Address라고 한다.
        - STUN 클라이언트는 SIP 메시지와 RTP 메시지에 Reflexive Transport Address를 사용한다.
        - STUN이 항상 효과적이지는 않다.
            - 두 단말이 같은 NAT 환경에 있을 경우, STUN은 동작하지 않는다.
            - Symmetric NAT로 동작하는 사설망 환경에서는 어플리케이션이 다르면 NAT 매핑 테이블이 바뀌기 때문에 사용할 수 없다.
            - STUN 메시지로 확인한 STUN 클라이언트의 Reflexive Transport Address가 다른 어플리케이션인 SIP 시그널링과 RTP 프로토콜을 사용할 때는 주소가 바뀐다.
    - TURN 서버
        - TURN 프로토콜은 NAT 환경에 단말이 릴레이 서버를 이용하여 통신하게 한다.
        - TURN 클라이언트는 사설 망에 위치하고 TURN 서버는 인터넷망에 위치한다.
        - TURN 클라이언트는 통화를 할 peer들과 직접 통신하는 것이 아니라 릴레이 서버 역할을 하는 TURN 서버를 경유한다.
        - TURN 클라이언트는 사설 주소 ( Host Transport Address ) 포함된 TURN 메시지를 TURN 서버로 전송한다.
        - TURN 서버는 TURN 메시지에 포함된 사설 주소와 TURN 메시지 패킷의 공인 주소인 layer 3 IP 주소와 layer 4 UDP 포트 넘버의 차이를 확인한다.
        - TURN 서버는 TURN 클라이언트 공인 주소 ( Server reflexive transport address )로 응답한다.
        - NAT 장비는 NAT 매핑 테이블에 있는 정보에 따라 TURN 응답 메시지를 클라이언트의 사설 주소로 전송한다.
        - TURN 서버는 릴레이 역할을 하는 서버의 공인 주소 (Relay Transport address)를 할당하는 역할을 하며 대규모 전개가 아니라면 TURN 서버와 릴레이 서버는 동일한 서버이다.
    - ICE ( Interactive Connectivity Establishment )
        - ICE를 실행하는 단말들은 통신이 가능한 모든 주소를 식별한다.
        - 처음에 클라이언트는 STUN 메시지를 TURN 서버로 전송하고 수신하는 과정에서 릴레이 주소를 확인한다.
            - 릴레이 주소는 TURN 서버가 패킷 릴레이를 위해 할당하는 주소
        - Candidate는 IP 주소와 포트 넘버의 조합으로 표시된 주소를 의미
        - TURN 서버는 Relayed Candidate와 Server Reflexive Candidate ( 단말의 공인 IP 주소)를 응답합니다.
        - 결국 사설망에 있는 단말은 3개의 통신 가능한 주소를 획득한다.
            - Local Address
                - 자신의 사설 IP 주소와 포트 넘버
            - Server Reflexive Address
                - 자신의 공인 IP 주소와 포트 넘버
            - Relayed Address
                - TURN 서버의 IP 주소와 포트 넘버
        - 만약 단말이 인터넷 망에 있다면 Local Address와 Server Reflexive Address는 동일하다.
        - 두 단말이 각각 3개의 주소를 가지고 있고, 서로가 상대방의 주소 수집으로 알 수 있다.
        - 그러면 Local - Local, Server reflexive - Server reflexive, relayed - relayed 간의 연결이 가능하다.
        - 또한 한 단말의 Local과 다른 단말의 Server reflexive와도 연결이 가능
        - ICE Candidate Gathering은 SDP Offer에 3개의 Candidate와 SDP Answer에 3개의 Candidate를 우선 순위를 정하여 교환하는 것
        - ICE 연결성 체크
            - 두 단말은 TURN 서버와 메시지 교환을 통해 자신의 3개의 Candidate 주소를 확인하고 SDP Offer와 SDP Answer를 통해 상대방의 3개 Candidate 주소를 확인한다.
            - 상대방의 Candidate와 자신의 Candidate로 실제 사용할 RTP와 RTCP 통신이 가능한지를 확인한다.
            - 주어진 모든 Candidate에 대한 확인을 마치고 나면 사용 가능한 주소 리스트가 만들어진다.
    - TURN 서버는 STUN 서버의 개념을 포함하고 있는 superset이며 STUN 서버처럼 단순히 라우팅 테이블을 통해서 private ip와 public ip를 연결하는데에서 그치지 않는다.
    - WebRTC를 예로 들면 미디어 데이터를 1:1로 보내준다고 했을 때 그 모든 데이터는 TURN 서버를 Relay 서버로 하여 데이터를 원하는 peer에게 전달해주게 된다.
    - 하지만, 만약 1:N 통신으로 스트리밍하는 서비스라면 중간에 Media 서버를 두어 중계하지 않으면 모든 peer가 매쉬 구조로 연결되게 되어 각 peer에 엄청난 부담을 주게 되고 네트워크 자원도 너무 많이 사용한다.
        - 이것을 해결하는 MCU와 SFU 방식이 있다.
