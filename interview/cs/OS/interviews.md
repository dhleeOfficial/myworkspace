# process vs thread
    - process
        - 실행중인 프로그램
        - 디스크로부터 메모리로 적재되어 CPU의 할당을 받을 수 있다.
        - 생성될 때 각각 별도의 주소 공간에 할당되며, code, data, heap, stack 영역을 가지고 있다.
        - Multi-Process의 장점은 각 프로세스간 독립적으로 동작하기 때문에 서로 영향을 끼치지 않는다. 하지만 각각 독립된 메모리 영역을 가지고 있어 다른 프로세스와 데이터 공유 간 IPC를 해야하는 경우 오버헤드가 있으며, Context Switching에 대한 오버헤드도 존재한다.
        - 프로세스는 최소 1개의 메인 스레드를 가지고 있다.
    - thread
        - 프로세스의 실행 단위
        - 스레드는 다른 스레드와 공간, 자원을 공유한다.
        - 멀티 스레드의 장점은 전역 변수와 정적 변수에 대한 자료를 공유한다.
        - 단점은 하나의 스레드가 다른 스레드에 영향을 끼칠 수 있으며 동기화에 신경 써야한다.
    - 프로세스가 생성되면 PCB라는 프로세스 제어 블록이 생성된다.
        - 여기에는 PID, status, info가 저장되어 있으며 context switching이 발생하면 현재 작업 정보를 저장하고 다시 CPU를 할당받으면 PCB로부터 이전의 작업 정보를 불러온다.
        - thread는 프로세스 내에서 stack만 할당 받고, code, data, heap 영역은 공유함

# code, data, stack, heap
    - code
        - 프로그램의 소스 코드를 저장
    - data
        - 전역 변수, 정적 변수 저장
    - stack
        - 함수, 지역 변수 저장
    - heap
        - 동적으로 할당한 것을 저장

# context switching
    - 인터럽트를 발생시켜 CPU에서 실행 중인 프로세스를 중단하고, 다른 프로세스를 처리하기 위한 과정
    - 현재 실행중인 프로세스의 context를 먼저 저장하고, 다음 프로세스를 동작시켜 작업을 처리한 후에 이전의 저장된 프로세스의 상태를 다시 복구함
    - 여기서 인터럽트란 CPU가 프로세스를 실행하고 있을 때, 입출력 하드웨어 등의 장치나 예외상황이 발생하여 처리가 필요함을 CPU에게 알리는 것

# interrupt
    - 주변 장치의 입출력 요구나 하드웨어 이상 현상을 CPU에게 알려주는 역할을 하는 신호
    - 프로그램을 실행하는 도중에 예기치 않은 상황이 발생한 경우 현재 실행 중인 작업을 즉시 중단하고, 발생된 상황을 우선 처리한 후, 실행 중이던 작업으로 복귀하여 계속 처리하는 것
    - 인터럽트에는 입출력과 같은 외부 인터럽트, 오버플로우, 0으로 나누는 상황으로 인한 내부 인터럽트가 있다.

# scheduler
    - 장기 스케쥴러
        - 메모리와 디스크 사이의 스케쥴링을 담당
        - 프로세스에 메모리를 할당한다.
        - 프로세스에 메모리가 할당되면, 프로세스는 ready 상태가 된다.
    - 중기 스케쥴러
        - 여유 공간을 마련하기 위해 프로세스를 메모리에서 디스크로 스와핑한다.
        - 스와핑이 되면 해당 프로세스는 suspended 상태가 된다.
    - 단기 스케쥴러
        - CPU와 메모리 사이의 스케쥴링 담당
        - 프로세스의 CPU를 할당
        - 프로세스에 CPU가 할당되면, 프로세스는 running 상태가 된다.

# CPU 스케쥴러 ( 단기 스케쥴러 )
    - FCFS
        - 먼저 온 순서대로 처리하는 스케쥴링 방식
        - 비선점형 스케쥴링
        - 실행 시간이 긴 프로세스 때문에 뒤의 프로세스들이 밀리는 컨베이 효과가 발생하는 문제점이 있음
    - SJF
        - 짧은 작업 시간을 가진 프로세스를 먼저 처리하는 스케쥴링 방식
        - 비선점형 스케쥴링이며 작업 시간이 긴 프로세스가 계속 밀리는 starvation 효과가 발생하는 문제점이 있음
    - 우선순위 스케쥴링
        - 우선순위가 가장 높은 프로세스를 먼저 처리하는 스케쥴링 방식
        - 선점형 스케쥴링과 비선점형 스케쥴링 방식이 있다.
        - 선점형 스케쥴링
            - 더 높은 우선 순위의 프로세스가 도착하면, 해당 프로세스가 CPU를 선점하는 것
        - 비선점형 스케쥴링
            - 더 높은 우선 순위의 프로세스가 도착하면, queue에 맨 앞에 위치하는 것
        - 우선 순위가 낮은 것들이 밀리는 starvation 효과가 발생하는 문제점이 있으며, aging을 적용하여 이를 해결할 수 있다.
    - RR
        - 현대적인 CPU 스케쥴링 방식으로 각 프로세스는 동일한 크기의 할당 시간인 time quantum을 갖는다.
        - 이 때 time quantum이 너무 커지면 FCFS와 같아져 컨베이 효과가 발생하고 너무 작아지면 잦은 context switch로 오버헤드가 발생한다.
        - 적당한 time quantum을 설정하는 것이 중요함

# cache
    - CPU와 메모리 사이의 속도 차이를 해결하기 위한 방법
    - cache 적중률( hit )을 높이기 위해 지역성의 원리를 기반한다.
    - 시간 지역성
        - 참조한 주소는 다시 참조할 확률이 높다는 것
    - 공간 지역성
        - 최근 참조한 주소의 주변 주소를 참조할 확률이 높다는 것
    - cache line은 캐시에 데이터를 저장할 때 자료구조를 활용해 묶어서 저장하는 것을 말하며 캐시에 저장하는 데이터에 데이터의 메모리 주소를 함께 저장하면서 빠르게 원하는 정보를 찾을 수 있다.

# semaphore & mutex
    - semaphore
        - 세마포어는 공유 자원을 여러 프로세스가 접근하는 것을 막는 것
        - 카운팅 세마포어의 경우 가용한 개수를 가진 자원에 대한 접근 제어용으로 사용되며, 자원을 사용하면 세마포어가 감소하고 방출하면 세마포어가 증가한다.
    - mutex
        - 뮤텍스는 공유 자원을 여러 스레드가 접근하는 것을 막는다.
        - 뮤텍스는 상태가 0, 1로 이진 세마포어라고 부르기도 함

# Compiler
    - 소스 파일은 컴퓨터가 이해할 수 있는 언어가 아님!
    - 컴퓨터가 실제로 이해하고 실행하기 위해서 low-level 언어, 이진수 파일로 변환해줘야하는 과정을 거쳐야 하는데 이 과정을 Compiling이라고 하고 Compiler가 이를 수행함
    - 컴파일 과정 뒤에 생긴 low-level 언어의 파일이 목적 파일

# Linker와 Linking 과정
    - 이렇게 만들어진 목적 파일( Object File )들을 링커가 링킹해서 실행 파일을 만든다.
    - 소스코드 양이 그만큼 늘어남에 따라 한 파일에 모든 소스코드를 작성할 수 없다.
        - 그래서 파일들을 분리해서 관리함
    - 링커라는 프로그램은..
        - 1. 컴파일이 거친 소스 코드 파일들을 하나로 합침 ( Object 파일들을 하나로 합침 )
        - 2. 여기에 Library를 합친 뒤 실행 파일을 만든다.
            - cout이라던지.. #include 같은거
        - 이 과정이 static linking

# Static Linking
    - 실행 파일을 만들 때 라이브러리를 같이 포함시켜서 .exe 파일을 만드는 것을 static linking이라고 한다.
    - 정적 라이브러리를 사용하여 컴파일을 하면 링커가 프로그램이 필요로 하는 부분을 라이브러리에서 찾아 실행 파일에다가 바로 복사한다.
    - 실행 파일에 다 들어가기 때문에 라이브러리가 필요 없으며 미리 컴파일 되어있기 때문에 컴파일 시간도 단축된다.
    - 하지만 실행 파일 내에 라이브러리 코드가 저장되기 때문에 메모리를 많이 잡아먹는다.
        - ex>
            - Hello world를 C++ 라이브러리랑 같이 링킹을 해서 실행을 했는데 메모리에 DLL파일이 없네?
            - 실행을 못하니까 OS가 메모리에 DLL 파일을 로드시켜준다.
            - 이렇게 메모리에 한 번 올라가면 그 다음부터는 이 올라가있는 DLL이 수행된다. ( shared libraries )
    - 동적 라이브러리는 프로그램이 실행될 때 링크된다.
    - Window에서는 DLL이라 부르고, Linux/Unix에서는 Shared Library라고 부르기 때문에 .so or .sa라고 쓴다.
    - 장단점
        - 메모리의 요구 사항이 훨씬 적다.
            - static linking의 경우 라이브러리 정보를 실행 프로그램당 메모리에 하나씩 다 올리지만 dynamic linking의 경우 동시에 유저가 프로그램을 몇 개를 실행 시키던 한 개만 올라간다.
        - dynamic linking은 프로그램 영역에서 라이브러리가 저장되어 있는 주소로 점프하는 것이기 때문에 성능상 overhead가 든다.
        

# Dynamic Linking
    - Static Linking을 썼더니 메모리에 쓸데없이 똑같은게 너무 많이 올라가더라..
    - 그런 라이브러리는 메모리에 하나만 올리자!
    - 그런 다음 이 프로그램이 cout을 호출할 때 메모리에 있는 cout으로 점프해 그쪽으로 간 후 실행한 다음에 다시 돌아오게 하자!가 Dynamic Linking
    - 

# paging & segmenation
    - paging
        - 고정 분할 방식
        - 물리 주소 공간을 같은 크기로 나누어 사용
        - 내부 단편화 발생
    - segmenation
        - 가변 분할 방식
        - 각 프로세스는 여러 세그먼트들로 나뉜다.
        - 외부 단편화 발생

# OS의 메모리 관리
    - OS는 어떤 프로그램에 얼마만큼의 메모리를 할당해야 할지를 결정해야함
        - 균등 할당
            - 프로세스마다 동일한 메모리를 할당하는 방식
        - 비례 할당
            - 프로세스의 크기에 비례하게 메모리를 할당하는 방식
        - 우선순위 할당
            - 우선순위가 높은 프로세스에게 더 많은 메모리를 할당하는 방식
    - OS는 프로세스를 통째로 메모리에 올릴 수 있지만 CPU에서 당장 수행해야 할 부분만 메모리에 올리고 나머지는 디스크의 swap 영역에 두어 메모리를 효율적으로 사용한다.

# Virtual Memory
    - OS는 프로그램이 자기 자신만의 가상 메모리를 사용하는 것처럼 가정해 프로그램하는 것을 지원한다.
    - 가상 메모리 주소 공간은 논리적 주소로서 모든 프로그램마다 0부터 시작하게 된다.
    - 즉 가상 메모리는 프로세스마다 논리적 주소 공간을 가지고 이 주소 공간의 일부는 물리적 메모리에 적재되고 일부는 스왑영역에 존재한다.
    - 장점
        - 메모리 사용량 감소 ( 프로세스 일부만 올림 )
        - 입출력 오버헤드 감소
        - 시스템이 더 많은 프로세스를 수용할 수 있다.
        - 프로그램이 물리적 메모리의 용량 제약에서 자유롭다.
    - 가상 메모리 기법은 프로세스 주소 공간을 적재하는 단위에 따라 요구 페이징 기법과 요구 세그멘테이션 기법 두 개로 나뉜다.

# 요구 페이징 기법
    - Page 단위로 프로세스의 주소 공간을 메모리에 적재하며 당장 사용될 페이지만을 메모리에 적재한다.
    - 프로세스를 일정 크기인 페이지로 잘라서 메모리에 적재하는 방식

# Deadlock
    - 서로가 상대방이 자원을 내놓기를 바라면서 무기한 연기 상황에 빠지는 것을 교착상태에 걸렸다라고 표현함
    - 특히 멀티 스레드 앱 개발자들은 데드락의 가능성을 개발할 때 항상 염두해두고 있어야 함
        - 여러 스레드에서 하나의 자원을 공유하는 경우가 많아 데드락 문제가 발생할 수 있기 때문이다.
    - Deadlock 발생 필요 조건
        - 1. Mutual Exclusion ( 상호 배제 )
            - 프로세서들이 자원을 배타적 점유, 다른 프로세스들이 자원 사용 불가, 한 번에 한 프로세스만이 자원 사용 가능
        - 2. Hold and wait ( 점유와 대기 )
            - 부분 할당, 다른 종류의 자원을 부가적으로 요구하면서 이미 어떤 자원을 점유하고 있음
        - 3. No preemption ( 비선점 )
            - 지원들은 그들이 점유하고 있는 프로세스로부터 도중에 해체되지 않음
        - 4. Circular wait ( 환형대기 )
            - 프로세스와 자원들이 원형을 이루며, 각 프로세스는 자신에게 할당된 자원을 가지면서  상대방 프로세스의 자원을 상호 요청하는 경우
    - Handling deadlock
        - 1. Prevention
            - 교착 상태의 필요조건을 부정함으로써 교착 상태가 발생하지 않도록 미리 예방하는 방법
        - 2. Avoidance
            - 교착 상태 가능성을 배제하지 않고 적절하게 피해나가는 방법
        - 3. Detection
            - 교착 상태 발생을 허용하고 발생 시 원인을 규명하여 해결하는 방법
        - 4. Recovory
            - 교착 상태 발견 후 환형 대기를 배제시키거나 자원을 중단하는 메모리 할당 기법

# Swapping
    - 프로세스는 실행되려면 반드시 메모리에 올라가야한다.
    - 근데 프로세스는 메모리에서 잠깐 뒤 저장공간으로 빠졌다가 다시 메모리에 돌아왔다가 이런식으로 실행됨에 따라 교체될 수 있다.
    - 주기억장치에 적재한 하나의 프로세스와 보조기억장치에 적재한 다른 프로세스의 메모리를 교체하는 기법

# 물리적 주소란?
    - RAM이라고 생각하면 됨

# MMU
    - CPU 코어 안에 탑재되어 가상 주소를 실제 메모리 주소로 변환해주는 장치

# 외부 단편화
    - 총 공간을 계산해봤을 때 요청을 만족할만한 충분한 메모리가 있음에도, 가능한 공간들이 연속적이지 않을 때 ( 즉 저장공간이 많은 작은 hole들로 조각조각 나있을 때 ) 발생
    - 해결 방안
        - 비어있는 공간을 연속적인 공간으로 만들고 움직이는 작업을 compaction이라고 함
    - 프로세스를 메모리 상 어디에 넣는게 효율적일까?
    - fit하게 넣는 방법을 생각해보자!
        - first fit
            - 가장 최초로 발견되는 hole에다가 할당하는 것
            - 남은 메모리를 앞에서부터 순차적으로 탐색하게 되는데, 이 프로세스가 들어갈 수 있는 hole들 중 최초에 발견된 hole에다가 배치하는 것
        - best fit
            - 어차피 자투리가 생기는데 가급적이면 자투리를 조그맣게 만들겠다!
        - worst fit
            - 가장 큰 공간, 가장 남는 공간에다가 넣는게 worst fit
    - 외부 단편화 문제 때문에 자투리 공간이 생겨서 쓸데없는 공간이 너무 많다! 메모리는 비싼 자원이다! -> paging 기법
        - 모든 프로세스 크기가 동일한게 아니니 결론적으로 프로세스 크기가 제각각일 경우, 외부 단편화 발생을 막을 수 없다는 것!
        - paging으로 메모리를 고정된 크기로 할당시키는 것!
            - 이 paging 기법으로 내부 단편화가 발생한다.

# paging
    - 프로세스를 일정 크기인 페이지로 잘라서 메모리에 적재하는 방식
    - 그러나 이 경우에는 프로세스가 page 크기에 맞게 딱 등분이 되지 않을 수도 있다. ( 내부 단편화 )
    - Logical address space를 동일한 크기로 나눈 것을 page라 부르고, physical memory를 나눈 것을 frame이라고 한다.
    - 프로세스의 물리적 주소 공간은 연속적이지 않을 수 있다.
    - 그렇기 때문에 조각조각난 page들을 문제없이 수행하기 위해, 즉 linear으로 쭉 수행시켜줄 수 있도록 도와주기 위해 page table이란 것이 있다.

# page table
    - 프로세스마다 페이지 테이블을 가지고 있다.
    - 배열과 같으며, 인덱스가 페이지 번호를 가리키고 그 배열에 담고 있는 숫자가 매핑할 프레임 번호

# TLB ( Translation Lookup Block )
    - 일종의 page table의 cache
    - page table은 메인 메모리에 저장되기 때문에 프로그램의 의한 모든 메모리 접근은 최소 두 번 필요하게 된다.
        - 실제 주소를 얻기 위한 메모리 주소 접근
        - 데이터를 얻기 위한 또 한번의 접근
        - CPU로 부터 가상 주소를 생성해서 이 주소를 캐시와 메모리에 매핑하기 위해서는 메모리에 있는 페이지 테이블을 통해 가상주소를 실제주소로 바꾸어야 가능함
        - 그래서 먼저 가상 주소를 메모리에 있는 페이지 테이블에 매핑시켜 실제 주소를 알아낸다.
            - 만약, 테이블의 valid bit가 0이라면 메모리에 페이지가 없으므로 page fault 발생.
        - 알아낸 실제 주소를 사용해서 cache로 가서 페이지가 있는지 비교해서 있다면 cache hit이 되고 없다면 cache miss가 되서 다시 메모리에서 페이지를 가져옴